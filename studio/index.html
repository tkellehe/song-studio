<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>Song Studio - Styler</title>
  <style>
    /* General reset */
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background-color: #121212;
      color: #ffffff;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
    }

    /* Header styles */
    header {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-bottom: 20px;
    }

    header img {
      width: 50px;
      height: 50px;
    }

    header h1 {
      font-size: 2rem;
    }

    /* Input and output areas */
    .container {
      width: 90%;
      max-width: 600px;
      display: flex;
      flex-direction: column;
      gap: 15px;
    }

    textarea {
      width: 100%;
      padding: 10px;
      border: 2px solid;
      border-image-slice: 1;
      border-width: 4px;
      border-image-source: linear-gradient(45deg, #06b6d4, #ec4899);
      border-radius: 5px;
      background-color: #1e1e1e;
      color: #ffffff;
      resize: none;
      font-size: 1rem;
      line-height: 1.5;
    }

    textarea:focus {
      outline: none;
      box-shadow: 0 0 10px #06b6d4;
    }

    input {
      width: 100%;
      padding: 10px;
      font-size: 1rem;
      border: 2px solid #06b6d4;
      border-radius: 5px;
      background-color: #1e1e1e;
      color: #ffffff;
    }

    input:focus {
      outline: none;
      box-shadow: 0 0 10px #06b6d4;
    }
  </style>
  <!-- TensorFlow.js and USE model scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder"></script>
</head>
<body>
  <header>
    <img src="../assets/note-gradient-icon.svg" alt="Note Icon">
    <h1>Song Studio - Styler</h1>
  </header>
  <div class="container">
    <input type="text" id="prompt-input" placeholder="Enter your prompt here">
    <textarea id="include-tags" placeholder="Include Tags" rows="5" readonly></textarea>
    <textarea id="exclude-tags" placeholder="Exclude Tags" rows="5" readonly></textarea>
  </div>

  <script>
    let timeoutId;
    let model, modelDescriptors;
    let cachedDescriptors = null; // For caching the loaded descriptors array

    //==========================//
    //    Model Loading
    //==========================//

    // Load the Universal Sentence Encoder model
    async function loadModel() {
      if (!model) {
        model = await use.load();
        console.log('USE Model loaded');
      }
      return model;
    }

    // Load the descriptors model for stacking embeddings
    async function loadDescriptorsModel() {
      if (!modelDescriptors) {
        const response = await fetch('../models/v0.1/model-descriptors.json');
        const jsonData = await response.json();
        modelDescriptors = jsonData;
        modelDescriptors.tfo = tf.tensor(jsonData.data, jsonData.shape, jsonData.dtype);
        console.log('Descriptors Model loaded');
      }
      return modelDescriptors;
    }

    //==========================//
    //   Descriptor Functions
    //==========================//

    // Load descriptors array (the "descriptors" property from the JSON)
    async function loadDescriptors() {
      if (!cachedDescriptors) {
        const response = await fetch('../models/v0.1/descriptors.json');
        const data = await response.json();
        // The JSON is in the form { "descriptors": [ ... ] }
        cachedDescriptors = data.descriptors; 
        console.log('Descriptors loaded');
      }
      return cachedDescriptors;
    }

    // Return the single big tensor from the descriptors model
    async function getStackedEmbeddings() {
      await loadDescriptorsModel();
      return modelDescriptors.tfo; 
    }

    function buildDescriptorStrings(descriptorArray) {
      const categories = {};
      descriptorArray.forEach(descriptor => {
        if (!categories[descriptor.category]) {
          categories[descriptor.category] = {
            count: 0,
            groups: {}
          };
        }
        const category = categories[descriptor.category];
        if (!category.groups[descriptor.group]) {
          category.groups[descriptor.group] = [];
        }
        category.groups[descriptor.group].push(descriptor);
        category.count++;
      });

      const descriptorStrings = [];

      // For each category, collect group tags and build output string
      for (const categoryName in categories) {
        const categoryData = categories[categoryName];
        for (const groupName in categoryData.groups) {
          const groupData = categoryData.groups[groupName];
          const concatList = [groupName];
          for (const descriptor of groupData) {
            if (descriptor.tag !== groupName) {
              concatList.push(descriptor.tag);
            }
          }
          descriptorStrings.push(concatList.join(' '));
        }
      }
      return descriptorStrings;
    }

    async function dotProductTensor(embedding) {
      // Get stacked descriptor embeddings
      const stackedDescriptors = await getStackedEmbeddings();

      // Keep track of tensors to dispose
      const tensorsToDispose = [];

      try {
        // Compute dot product between query embedding and each descriptor embedding
        const dotProducts = tf.matMul(embedding, stackedDescriptors, false, true);
        tensorsToDispose.push(dotProducts);
        // Shape of dotProducts is [1, num_descriptors], so we squeeze to [num_descriptors]
        return dotProducts.squeeze();
      } finally {
        // Dispose of intermediate tensors
        tensorsToDispose.forEach(tensor => tensor.dispose());
      }
    }

    async function queryDescriptors(embedding, topN, bottomN) {
      // Always fetch the descriptors array from loadDescriptors
      const descriptorArray = await loadDescriptors();

      const scores = await dotProductTensor(embedding);
      // Keep track of tensors to dispose
      const tensorsToDispose = [scores];

      try {
        // Get top N
        const { indices: topIndices, values: topValues } = tf.topk(scores, topN);
        // For bottom N, multiply by -1 and do topk
        const invertedScores = scores.mul(tf.scalar(-1));
        const { indices: bottomIndices, values: bottomValues } = tf.topk(invertedScores, bottomN);

        // Add all to disposal list
        tensorsToDispose.push(topIndices, topValues, bottomIndices, bottomValues, invertedScores);

        // Convert typed arrays
        const topIndicesArray = topIndices.dataSync();
        const bottomIndicesArray = bottomIndices.dataSync();

        // Build arrays from top and bottom indices
        const tops = [];
        for (let i = 0; i < topN; i++) {
          tops.push(descriptorArray[topIndicesArray[i]]);
        }

        const bottoms = [];
        for (let i = 0; i < bottomN; i++) {
          bottoms.push(descriptorArray[bottomIndicesArray[i]]);
        }

        return { tops, bottoms };
      } finally {
        // Dispose of intermediate tensors
        tensorsToDispose.forEach(tensor => tensor.dispose());
      }
    }

    //==========================//
    //     Utility Functions
    //==========================//

    // Get embedding for a given text using the loaded USE model
    async function getEmbedding(text) {
      const useModel = await loadModel();
      return useModel.embed(text);
    }

    // Build descriptors based on "similarity" (dot product in this case)
    async function buildCustomDescriptor(text, topN = 10, bottomN = 5) {
      const embedding = await getEmbedding(text);
      const { tops, bottoms } = await queryDescriptors(embedding, topN, bottomN);
      return {
        include: buildDescriptorStrings(tops),
        exclude: buildDescriptorStrings(bottoms),
      };
    }

    //==========================//
    //      Main Execution
    //==========================//

    // Debounced prompt input
    document.getElementById('prompt-input').addEventListener('input', (event) => {
      const text = event.target.value;

      clearTimeout(timeoutId);
      timeoutId = setTimeout(async () => {
        if (text.trim().length > 0) {
          const descriptors = await buildCustomDescriptor(text);
          document.getElementById('include-tags').value = descriptors.include.join(', ');
          document.getElementById('exclude-tags').value = descriptors.exclude.join(', ');
        } else {
          document.getElementById('include-tags').value = '';
          document.getElementById('exclude-tags').value = '';
        }
      }, 300);
    });

    // Preload the model and descriptors on page load
    window.onload = async () => {
      // Load main USE model
      await loadModel();
      // Load descriptor embeddings (modelDescriptors) so they're ready
      await loadDescriptorsModel();
      // Pre-cache the descriptors array
      await loadDescriptors();
    };
  </script>
</body>
</html>
